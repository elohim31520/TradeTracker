{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在從 gemma3:4b 接收串流式應答 ---\n",
      "中國迅速侵蝕美國在全球 AI 競賽領導地位，是一個複雜且多層面的現象，涉及經濟、政治、技術和戰略等多個方面。以下是一個詳細的分析，分為幾個主要方面：\n",
      "\n",
      "**1. 政策支持與集中資源:**\n",
      "\n",
      "* **中央政府的優先級:** 中國政府將AI視為國家戰略發展的關鍵，並投入了前所未有的資源。習近平主席更是明確將AI定位為“第三次工業革命”，並在2017年發布了《新一代人工智能發展規劃》，將AI列為國家戰略發展重點，並建立了由李飛負責的中央AI戰略體系。\n",
      "* **集中資源的模式:** 與美國分散的投資相比，中國政府在AI領域進行了集中且高效的投資。這包括巨額的資金投入、人才招募、基礎設施建設和數據收集。\n",
      "* **五個關鍵領域的重點發展:** 中國政府將AI發展重點放在以下五個關鍵領域：AI基礎技術、智能交通、智能製造、智能醫療和智能能源。\n",
      "* **戰略目標明確:** 中國的目標不僅僅是提升技術水平，更重要的是在特定領域（例如自動駕駛、智能製造）中實現產業領先。\n",
      "\n",
      "**2. 數據的優勢:**\n",
      "\n",
      "* **龐大的數據資源:** 中國擁有全球最大的網路用戶群，這意味著有大量的數據可用於訓練AI模型。 數據是AI發展的燃料，中國憑藉其龐大的數據量，在早期AI發展中獲得了顯著優勢。\n",
      "* **數據收集的自由度:** 相較於美國，中國政府對數據收集和使用有更大的自由度，這使得企業更容易獲得數據資源。\n",
      "* **數據治理的挑戰:**  雖然數據優勢顯著，但中國也面臨數據治理和隱私保護方面的挑戰，這可能會影響長期AI發展。\n",
      "\n",
      "**3.  技術進步與創新:**\n",
      "\n",
      "* **早期先發優勢:** 在早期，中國在某些AI領域（例如人臉識別、語音識別）方面取得了顯著的技術突破，並在商業上迅速應用。\n",
      "* **大規模訓練的領先:**  中國在更大規模的AI模型訓練方面表現出色，並快速發展了相關技術。\n",
      "* **算法創新:**  雖然在算法創新方面與美國並非完全對等，但在特定應用場景下的算法優化方面，中國企業表現出色。\n",
      "* **AI+應用:**  中國企業迅速將AI技術應用於各個行業，例如製造、金融、農業等，形成了一系列“AI+”應用案例。\n",
      "\n",
      "**4.  人才招募:**\n",
      "\n",
      "* **“去海外招聘”策略:**  中國政府推行“去海外招聘”政策，吸引了大量海外AI人才回國，特別是來自美國、歐洲和加拿大的研究人員和工程師。\n",
      "* **人才培養:**  中國加大了在AI人才培養方面的投入，通過優化教育體系和支持企業開展AI研究，提升人才數量和質量。\n",
      "\n",
      "**5.  美國的反應與挑戰:**\n",
      "\n",
      "* **分散的投資模式:**  與中國集中資源的模式不同，美國的AI投資分散在大學、研究機構和企業之間。\n",
      "* **數據隱私和監管問題:**  美國對數據隱私和AI監管更加嚴格，這增加了企業進行大規模數據收集和AI模型的訓練的成本和風險。\n",
      "* **地緣政治競爭:**  美國將AI戰略與地緣政治聯繫起來，以應對中國的崛起。\n",
      "* **人才流失:**  部分AI人才因地緣政治因素或對美國監管環境的擔憂而選擇離開美國。\n",
      "\n",
      "**6.  戰略角度的考量:**\n",
      "\n",
      "* **軍事應用:**  中國將AI視為提升軍事力量的關鍵技術，並加大了在軍事AI領域的投入。\n",
      "* **全球影響力:**  中國積極推動“去美元化”，並將AI技術應用於全球貿易和金融領域，以提升其在全球經濟中的影響力。\n",
      "\n",
      "**結論:**\n",
      "\n",
      "中國迅速侵蝕美國在全球AI競賽領導地位，主要是由于其政府的強烈支持、龐大的數據資源、人才招募策略以及在特定領域的快速發展。然而，美國在技術創新、算法優化和全球影響力方面仍然具有優勢。  AI的發展是一個持續的競爭過程，未來幾年，中美在AI領域的競爭將更加激烈。\n",
      "\n",
      "**未來趨勢:**\n",
      "\n",
      "*   **監管的調整:**  美國和中國都可能在AI監管方面進行調整，以平衡技術創新和社會責任。\n",
      "*   **全球合作:**  國際合作對於AI的健康發展至關重要，但地緣政治競爭可能會影響合作的程度。\n",
      "*   **技術的演進:**  AI技術的快速演進將帶來新的機會和挑戰，各國需要不斷學習和適應。\n",
      "\n",
      "希望這個詳細的分析能幫助您更好地理解這個複雜的問題。 為了更深入的理解，建議您查閱相關的研究報告、新聞報導和學術文章。\n",
      "\n",
      "\n",
      "--- 串流結束 ---\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "ollama_api_url = 'http://localhost:11434/api/chat'\n",
    "\n",
    "def stream_ollama_response(model, prompt):\n",
    "    # 為 /api/chat 端點準備請求的 payload\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with requests.post(ollama_api_url, json=payload, stream=True) as response:\n",
    "            # 檢查請求是否成功\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # 逐行迭代回應內容\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        # 每一行都是一個獨立的 JSON 物件\n",
    "                        json_data = json.loads(line.decode('utf-8'))\n",
    "                        \n",
    "                        # 從 'message' 物件中提取 'content'\n",
    "                        content_chunk = json_data.get('message', {}).get('content', '')\n",
    "                        \n",
    "                        # 使用 yield 回傳每一塊內容\n",
    "                        yield content_chunk\n",
    "                        \n",
    "                        # 最後一個 JSON 物件會有一個 'done' 欄位為 true\n",
    "                        if json_data.get('done'):\n",
    "                            break\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"\\n[警告] 無法解析的 JSON 行: {line}\")\n",
    "                        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n[錯誤] 請求失敗: {e}\")\n",
    "\n",
    "# --- 如何使用 ---\n",
    "\n",
    "model_to_use = \"gemma3:4b\"\n",
    "user_prompt = \"中國迅速侵蝕美國全球 AI 競賽領導地位這件事，請提供詳細的分析。\"\n",
    "\n",
    "print(f\"--- 正在從 {model_to_use} 接收串流式應答 ---\")\n",
    "\n",
    "# for 迴圈會自動處理 generator，並在收到每個區塊時立即印出\n",
    "full_response = \"\"\n",
    "for chunk in stream_ollama_response(model_to_use, user_prompt):\n",
    "    print(chunk, end='', flush=True)\n",
    "    full_response += chunk\n",
    "\n",
    "print(\"\\n\\n--- 串流結束 ---\")\n",
    "# print(\"\\n完整的回應:\\n\", full_response) # 您也可以在最後檢視完整回應\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在從 gemma3:4b 接收串流式應答 ---\n",
      "這個程式碼片段使用了 Python 的 `requests` 函式庫，通過 `requests.post()` 方法發送 POST 請求，並且使用了 `stream=True` 參數，同時使用了 `with` 語句來管理資源（回應物件）。讓我們分解一下這個程式碼的每一部分：\n",
      "\n",
      "**1. `requests.post(ollama_api_url, json=payload, stream=True)`**\n",
      "\n",
      "* **`requests.post()`**:  這是 `requests` 函式庫的一個方法，用於發送 HTTP POST 請求。  這意味著你正在向一個指定的 URL 發送數據，並期望伺服器對該數據做出回應。\n",
      "* **`ollama_api_url`**: 這是目標伺服器的 URL。  `requests.post()` 方法會將這個 URL 作為請求的目的地。  `ollama_api_url` 應該是一個字符串，包含 API 的網址。\n",
      "* **`json=payload`**:  這部分告訴 `requests` 函式庫將 `payload` 變數（通常是一個字典）作為 JSON 格式的數據發送。 `requests` 會自動將這個字典轉換為 JSON 字符串，並將其包含在 POST 請求的請求體（body）中。  這是向 API 傳輸結構化數據的標準方式。\n",
      "* **`stream=True`**:  這是關鍵的部分。  當 `stream=True` 時，`requests` 函式庫不會立即下載整個回應的內容。  相反，它會將回應作為一個流（stream）返回。  這有幾個優點：\n",
      "    * **節省資源:**  特別是在處理大文件或大型數據流時，不下載整個內容可以節省大量的記憶體和時間。\n",
      "    * **增量處理:**  允許你逐步處理回應數據，例如，逐行讀取大型輸出流。\n",
      "    * **避免BufferOverflow:**  避免了將整個回應內容一次性讀取到記憶體中，從而降低了緩衝溢位的風險。\n",
      "\n",
      "**2. `with ... as response:`**\n",
      "\n",
      "* **`with` 語句**:  這是一種語句，用於管理資源，確保在程式碼塊執行完畢後，資源（例如文件、網路連接、檔案等）會被正確釋放。\n",
      "* **`... as response:`**:  `with` 語句會創建一個命名變數 `response`，來引用 `requests` 返回的 `response` 物件。  這使得你可以直接訪問和操作這個物件。\n",
      "* **`response` 物件**:  `response` 物件包含了關於 HTTP 響應的所有信息，例如：\n",
      "    * **`response.status_code`**: 響應的 HTTP 狀態碼（例如 200 表示成功，404 表示未找到）。\n",
      "    * **`response.headers`**: 響應的 HTTP 標頭。\n",
      "    * **`response.text`**: 響應的主體內容，通常是 HTML、JSON 或其他文本數據。\n",
      "    * **`response.json()`**: 如果響應的主體是有效的 JSON，則可以使用這個方法將其解析為 Python 字典。\n",
      "    * **`response.content`**:  響應的主體內容的原始字节数据。\n",
      "    * **`response.raw`**:  如果 `stream=True`，`response.raw` 會返回一個 `ResponseStream` 物件，用於流式地讀取回應數據。\n",
      "\n",
      "**總結：**\n",
      "\n",
      "這個程式碼片段通過 `requests.post()` 發送一個包含 JSON 數據的 POST 請求到 `ollama_api_url`。  `stream=True` 參數使得響應以流的形式返回，以便你可以逐步處理數據。  `with` 語句確保即使在出現錯誤的情況下， `response` 物件也會被正確釋放。  它通常用於處理大型數據流或需要逐行處理回應數據的場景。\n",
      "\n",
      "**例子：**\n",
      "\n",
      "假設 `ollama_api_url` 是 `https://api.ollama.com/v1/chat/complete`，並且 `payload` 是一個包含提示詞的字典：\n",
      "\n",
      "```python\n",
      "import requests\n",
      "import json\n",
      "\n",
      "ollama_api_url = \"https://api.ollama.com/v1/chat/complete\"\n",
      "payload = {\n",
      "    \"model\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "    \"prompt\": \"Hello, world!\",\n",
      "    \"stream\": True  # 確保啟用流式響應\n",
      "}\n",
      "\n",
      "try:\n",
      "    with requests.post(ollama_api_url, json=payload, stream=True) as response:\n",
      "        if response.status_code == 200:\n",
      "            for line in response.iter_lines(decode_unicode=True):  # 迭代流式響應\n",
      "                if line:\n",
      "                    print(line.strip())  # 處理每行響應數據\n",
      "        else:\n",
      "            print(f\"Error: {response.status_code}\")\n",
      "except requests.exceptions.RequestException as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "```\n",
      "\n",
      "在這個例子中，`response.iter_lines(decode_unicode=True)` 會迭代響應流，將每行數據（通常是 JSON 格式）以字符串的形式返回，並且`decode_unicode=True` 確保字符串被正確地編碼為 Unicode，從而可以處理包含非 ASCII 字符的數據。\n",
      "\n",
      "\n",
      "--- 串流結束 ---\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "ollama_api_url = 'http://localhost:1234/ollama/chat'\n",
    "\n",
    "def stream_ollama_response(model, prompt):\n",
    "    # 為 /api/chat 端點準備請求的 payload\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with requests.post(ollama_api_url, json=payload, stream=True) as response:\n",
    "            response.raise_for_status()\n",
    "\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        json_data = json.loads(line.decode('utf-8'))\n",
    "                        \n",
    "                        # 從 'message' 物件中提取 'content'\n",
    "                        content_chunk = json_data.get('message', {}).get('content', '')\n",
    "                        \n",
    "                        # 使用 yield 回傳每一塊內容\n",
    "                        yield content_chunk\n",
    "                        \n",
    "                        # 最後一個 JSON 物件會有一個 'done' 欄位為 true\n",
    "                        if json_data.get('done'):\n",
    "                            break\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"\\n[警告] 無法解析的 JSON 行: {line}\")\n",
    "                        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n[錯誤] 請求失敗: {e}\")\n",
    "\n",
    "# --- 如何使用 ---\n",
    "\n",
    "model_to_use = \"gemma3:4b\"\n",
    "user_prompt = \"解釋with requests.post(ollama_api_url, json=payload, stream=True) as response: with怎麼用？\"\n",
    "\n",
    "print(f\"--- 正在從 {model_to_use} 接收串流式應答 ---\")\n",
    "\n",
    "# for 迴圈會自動處理 generator，並在收到每個區塊時立即印出\n",
    "full_response = \"\"\n",
    "for chunk in stream_ollama_response(model_to_use, user_prompt):\n",
    "    print(chunk, end='', flush=True)\n",
    "    full_response += chunk\n",
    "\n",
    "print(\"\\n\\n--- 串流結束 ---\")\n",
    "# print(\"\\n完整的回應:\\n\", full_response) # 您也可以在最後檢視完整回應\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
